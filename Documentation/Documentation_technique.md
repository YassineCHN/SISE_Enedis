# ‚öôÔ∏è Documentation Technique ‚Äì GreenTech Solutions

## 1. Architecture g√©n√©rale

L‚Äôapplication **GreenTech Solutions** repose sur une architecture moderne combinant **Streamlit** pour l‚Äôinterface utilisateur et **FastAPI** pour le backend de pr√©diction.  
Elle est conteneuris√©e via **Docker** et d√©ploy√©e sur la plateforme **Koyeb**.

### Vue d‚Äôensemble

<img width="1920" height="1080" alt="M2SIA- Diapo soutenance  (1)" src="https://github.com/user-attachments/assets/5542a144-19c7-4909-b1fb-6d6650529701" />


### R√©partition des composants

| R√©pertoire | R√¥le principal |
|-------------|----------------|
| `api/` | API FastAPI : endpoints de pr√©diction et chargement des mod√®les |
| `Scripts/app/` | Application Streamlit (frontend) avec les pages et les utilitaires |
| `models/` | Mod√®les ML sauvegard√©s (`.pkl`) |
| `data/` | Jeux de donn√©es ADEME nettoy√©s (CSV) |
| `Hugging Face` | Stockage des datasets et mod√®les pour les rendre accessibles par l'app koyeb |
| `volume` | Stockage persistant des datasets et mod√®les sur koyeb |
| `Notebooks/` | Scripts de mod√©lisation (collecte, pr√©paration, entra√Ænement) |
| `Dockerfile` | Image combin√©e Streamlit + FastAPI |
| `koyeb.yaml` | Configuration de d√©ploiement sur Koyeb |

---

## 2. Composants logiciels

### 2.1 Backend ‚Äì FastAPI

**Fichier principal :** `api/main.py`  
**Objectif :** fournir des endpoints REST pour les pr√©dictions de DPE et de consommation.

**Endpoints principaux :**
| Endpoint | M√©thode | Description |
|-----------|----------|-------------|
| `/predict_dpe` | POST | Pr√©diction de la classe √©nerg√©tique (A‚ÄìG) |
| `/predict_conso` | POST | Pr√©diction de la consommation (kWh/m¬≤/an) |

**Modules :**
- `schemas.py` : D√©finition des sch√©mas Pydantic pour valider les requ√™tes
- `models_loader.py` : Chargement des mod√®les `.pkl` depuis le dossier `models/`
- `utils.py` : Fonctions utilitaires
- `config.py` : Param√®tres d‚Äôinitialisation

**Librairies cl√©s :** `fastapi`, `uvicorn`, `pydantic`, `joblib`, `scikit-learn`

---

### 2.2 Frontend ‚Äì Streamlit

**Point d‚Äôentr√©e :** `Scripts/app/main.py`  
**Framework :** Streamlit multi-pages

**Structure :**
- `pages/` : contient les pages Contexte, Exploration, Analyse, Cartographie, Pr√©diction, API
- `utils/` : fonctions partag√©es (pr√©processing, visualisation, chargement des donn√©es)
- `assets/` : images et ic√¥nes
- `config.py` : param√®tres g√©n√©raux (th√®me, titre, favicon, etc.)

**Librairies principales :** `streamlit`, `plotly`, `streamlit_folium`, `pandas`, `folium`, `pyproj`

---

## 3. Environnements et d√©pendances

**Python :** 3.12  
**Environnement virtuel :** `venv_enedis`

### Fichier `requirements.txt`
Inclut notamment :  
`streamlit`, `fastapi`, `uvicorn`, `scikit-learn`, `pandas`, `numpy`, `plotly`, `folium`, `requests`, `joblib`, `pydantic`, `pyproj`.

---

## 4. Ex√©cution du projet

### En local
```bash
# 1. Activer l'environnement virtuel
venv_enedis\Scripts\activate

# 2. Lancer l'API
uvicorn api.main:app --reload

# 3. Lancer Streamlit
streamlit run Scripts/app/main.py
```

**URL locales :**
- Streamlit : http://localhost:8501  
- API FastAPI : http://localhost:8000/docs

---
### üöÄ Ex√©cuter le projet avec Docker

Ce projet peut √™tre lanc√© de **deux mani√®res** :  
1) **Construire l‚Äôimage localement** √† partir du Dockerfile  
2) **T√©l√©charger l‚Äôimage publique** depuis Docker Hub

---

#### üß© Pr√©requis
- Docker install√© (Windows/macOS/Linux)
- Ports **8000** (API FastAPI) et **8501** (Streamlit) libres

---

#### ‚úÖ Option A ‚Äî Construire l‚Äôimage localement

```bash
# Se placer √† la racine du projet (l√† o√π se trouve le Dockerfile)
docker build -t dpe-app .

# Lancer le conteneur
docker run -p 8000:8000 -p 8501:8501 dpe-app
```

**Acc√®s locaux :**
- Streamlit : http://localhost:8501  
- API FastAPI : http://localhost:8000/docs

---

#### ‚úÖ Option B ‚Äî Utiliser l‚Äôimage publique (Docker Hub)

[![Docker Hub](https://img.shields.io/badge/Docker%20Hub-dpe--app-blue?logo=docker)](https://hub.docker.com/r/yassinechn/dpe-app)

T√©l√©chargez et lancez l‚Äôimage **sans d√©pendances locales** :

```bash
# T√©l√©charger l‚Äôimage publique
docker pull yassinechn/dpe-app:latest

# Lancer le conteneur
docker run -p 8000:8000 -p 8501:8501 yassinechn/dpe-app:latest
```

**Acc√®s locaux :**
- Streamlit : http://localhost:8501  
- API FastAPI : http://localhost:8000/docs

---

#### üì¶ D√©tails techniques de l‚Äôimage

| √âl√©ment | Valeur |
|---|---|
| **Image locale** | `dpe-app:latest` |
| **Image publique** | `yassinechn/dpe-app:latest` |
| **Base** | `python:3.12-slim` |
| **Taille indicative** | ‚âà 2.9 GB |
| **Ports expos√©s** | `8000` (FastAPI), `8501` (Streamlit) |
| **Volumes** | `/app/data`, `/app/models` |
| **Compatibilit√©** | Windows / macOS / Linux |

---

#### üõ†Ô∏è D√©pannage (FAQ rapide)

- **Port d√©j√† utilis√© (Bind for 0.0.0.0:8000 failed)**  
  ‚Üí Arr√™ter le service qui occupe le port ou changer le mapping, ex. :  
  ```bash
  docker run -p 8080:8000 -p 8501:8501 dpe-app
  ```
  Acc√®s API : http://localhost:8080/docs

- **Rebuild n√©cessaire apr√®s modification du code**  
  ‚Üí Reconstruire l‚Äôimage :  
  ```bash
  docker build -t dpe-app .
  ```
üí° *Cette image permet d‚Äôex√©cuter le projet complet
---

---

### D√©ploiement sur Koyeb

**Fichier :** `koyeb.yaml`

```yaml
name: dpe-streamlit-app
services:
  - name: dpe-streamlit
    type: web
    ports:
      - 8501
    routes:
      - path: /
    build_from_source: true
    dockerfile_path: ./Dockerfile
    volumes:
      - name: data-volume
        mount_path: /app/data
      - name: models-volume
        mount_path: /app/models
    env:
      - key: STREAMLIT_SERVER_PORT
        value: "8501"
      - key: PYTHONUNBUFFERED
        value: "1"
```

**Commandes ex√©cut√©es automatiquement :**
- D√©marrage de FastAPI (`uvicorn api.main:app`)  
- Lancement de Streamlit (`streamlit run Scripts/app/main.py`)

---

## 5. Maintenance et √©volution

| T√¢che | Localisation | Description |
|--------|---------------|--------------|
| üîÅ R√©entra√Ænement | `Notebooks/classification_new.ipynb` & `regression_new.ipynb` | R√©entra√Æner et sauvegarder les nouveaux mod√®les `.pkl` |
| üßπ Rafra√Æchissement des donn√©es | `Notebooks/collect_data_api.ipynb` | Mise √† jour depuis l‚ÄôAPI ADEME |
| üß∞ Mise √† jour d√©pendances | `requirements.txt` | `pip install -r requirements.txt` |
| üê≥ Reconstruction Docker | `Dockerfile` | `docker build -t dpe-app .` |
| ‚òÅÔ∏è Mise √† jour sur Koyeb | `koyeb.yaml` | Relancer le d√©ploiement avec `git push` |

---

## 6. Sch√©ma d‚Äôarchitecture ‚Äì GreenTech Solutions

L‚Äôarchitecture globale du projet **GreenTech Solutions** combine un pipeline **ETL complet**, un module de **mod√©lisation Machine Learning**, et une **application web conteneuris√©e** (Streamlit + FastAPI) d√©ploy√©e sur **Koyeb**.  
Elle int√®gre √©galement **Hugging Face** pour le stockage distant et la synchronisation automatique des mod√®les et jeux de donn√©es.
L‚Äôensemble est conteneuris√© via **Docker** et d√©ploy√© sur **Koyeb**.

---

### üß© 6.1 ‚Äì Pipeline ETL (Collecte, Transformation, Mod√©lisation)

Ce premier sch√©ma illustre le processus complet de pr√©paration des donn√©es et d‚Äôentra√Ænement des mod√®les :

1. **Collecte (Extract)**  
   - En d√©but de script on attribue (manuellement) une valeur d'un nombre entier √† la variable DEPT_CODE (qui dans le sch√©ma est appel√© "dept")  afin de choisir le d√©partement que l'on veut r√©cup√©rer
   - R√©cup√©ration des DPE *existants* et *neufs* via les **API publiques ADEME** (`dpe03existant`, `dpe02neuf`) √† l‚Äôaide de `requests` et `pandas` sur le DEPT_CODE renseign√©. 
   - Export en CSV (`donnees_dpe_[dept]_existants.csv`, `donnees_dpe_[dept]_neufs.csv`).

2. **Transformation (Transform)**  
   - Nettoyage, fusion, ajout de colonnes, conversion des coordonn√©es (Lambert93 ‚Üí WGS84).
   - Production du fichier propre `donnees_dpe_[dept]_clean.csv`.

3. **Mod√©lisation et entra√Ænement (Load/Restitution)**  
   - Entra√Ænement des mod√®les de **r√©gression** (consommation √©nerg√©tique) et de **classification** (√©tiquette DPE, √©ligibilit√© MaPrimeR√©nov‚Äô)  
   - Sauvegarde des mod√®les au format `.pkl` :  
     - `model_CONSO_Random_Forest.pkl`  
     - `model_DPE_Random_Forest.pkl`  
     - `model_MPR_Random_Forest.pkl`

4. **Publication sur Hugging Face (Synchronisation)**  
   - Les fichiers mod√®les et datasets nettoy√©s sont **envoy√©s sur le d√©p√¥t Hugging Face** pour √™tre accessibles publiquement lors du d√©ploiement sur Koyeb.  
   - Hugging Face agit comme **stockage distant partag√©** entre l‚Äôenvironnement local et le cloud.

üìò **Notebooks concern√©s :**  
`collect_data_api.ipynb`, `prepare_data.ipynb`, `regression_new.ipynb`, `classification_new.ipynb`

üß† **Technos principales :** `pandas`, `numpy`, `pyproj`, `scikit-learn`, `joblib`, `huggingface_hub`

üìä **Sch√©ma ETL :**
<img width="1920" height="1080" alt="M2SIA- Diapo soutenance  (3)" src="https://github.com/user-attachments/assets/6a3a333e-0308-4f06-9f65-86670c8cf133" />

---

### üíª 6.2 ‚Äì Architecture applicative (Streamlit + FastAPI)

L‚Äôapplication combine une interface utilisateur **Streamlit** et un backend **FastAPI**.  
Les deux sont lanc√©s simultan√©ment dans le m√™me conteneur Docker.

- **Streamlit** pour le front-end interactif (multi-pages)
- **FastAPI** pour le back-end de pr√©diction

**Fonctionnement g√©n√©ral :**
1. L‚Äôutilisateur interagit avec Streamlit √† travers plusieurs pages :  
   `/Contexte`, `/Exploration`, `/Analyse`, `/Cartographie`, `/Pr√©diction`, `/API`, `/Profil`
2. Lorsqu‚Äôune pr√©diction est demand√©e, Streamlit envoie une requ√™te HTTP √† FastAPI.
3. FastAPI charge les mod√®les `.pkl` et renvoie les r√©sultats √† Streamlit pour affichage.

**Chargement des mod√®les :**
- Au d√©marrage du conteneur, un script (`init_assets.py`) t√©l√©charge automatiquement les mod√®les et jeux de donn√©es depuis **Hugging Face** si absents du volume local.  
- Les fichiers sont ensuite plac√©s dans `/app/models` et `/app/data`.

**Endpoints FastAPI principaux :**
| M√©thode | Endpoint | Description |
|----------|-----------|-------------|
| `GET` | `/status` | V√©rifie la disponibilit√© du service |
| `GET` | `/last_update` | Indique la date de derni√®re mise √† jour des mod√®les |
| `GET` | `/predict_sample` | Fournit un exemple de pr√©diction |
| `POST` | `/predict_all` | R√©alise une pr√©diction compl√®te (DPE, consommation, MaPrimeR√©nov‚Äô) |

üåê **Ports utilis√©s :**
- `8501` ‚Üí Streamlit  
- `8000` ‚Üí FastAPI  

üìò **Dossiers concern√©s :**
- `/Scripts/app/` ‚Üí Interface Streamlit (frontend)  
- `/api/` ‚Üí API FastAPI (backend)  
- `/models/` ‚Üí Mod√®les ML `.pkl`  
- `/data/` ‚Üí Donn√©es ADEME nettoy√©es

üìä **Sch√©ma application :**
<img width="1920" height="1080" alt="M2SIA- Diapo soutenance " src="https://github.com/user-attachments/assets/4a6f9d5c-b203-4b48-95dc-46a41b10803b" />

---

### ‚òÅÔ∏è 6.3 ‚Äì D√©ploiement global (Docker + Koyeb + Hugging Face)

L‚Äôensemble de la solution est conteneuris√© et d√©ploy√© sur la plateforme **Koyeb** √† l‚Äôaide du `Dockerfile` et du fichier `koyeb.yaml`.

**√âtapes de fonctionnement :**

1. **Construction Docker** : le Dockerfile cr√©e une image contenant Streamlit, FastAPI et les d√©pendances ML.  
2. **Synchronisation avec Hugging Face** : lors du d√©marrage, les mod√®les et donn√©es sont automatiquement t√©l√©charg√©s dans les volumes `/app/data` et `/app/models`.  
3. **D√©ploiement Koyeb** : la plateforme lance le conteneur, expose les ports 8501 (Streamlit) et 8000 (FastAPI) et monte les volumes persistants.  
4. **Acc√®s utilisateur** : via l‚ÄôURL publique Koyeb.

üì¶ **Technos cl√©s :** `Docker`, `Koyeb`, `Hugging Face`, `FastAPI`, `Streamlit`

üìä **Sch√©ma global :**
<img width="1920" height="1080" alt="M2SIA- Diapo soutenance  (1)" src="https://github.com/user-attachments/assets/5542a144-19c7-4909-b1fb-6d6650529701" />

---

### üîÅ R√©sum√© des interactions

| √âtape | Entr√©es | Sorties | Technologies |
|--------|----------|----------|---------------|
| Collecte | API ADEME | CSV bruts | `requests`, `pandas` |
| Pr√©paration | CSV bruts | `donnees_dpe_clean.csv` | `pandas`, `pyproj` |
| Mod√©lisation | CSV clean | `.pkl` (mod√®les ML) | `scikit-learn`, `joblib` |
| Publication | `.pkl` + CSV clean | Hugging Face Hub | `huggingface_hub` |
| Application | `.pkl` + donn√©es | Interface Streamlit + API | `Streamlit`, `FastAPI` |
| D√©ploiement | Dockerfile + volumes | Service web Koyeb | `Docker`, `Koyeb` |

---

üí° *Hugging Face sert ici de pont entre l‚Äôenvironnement local et le cloud : les mod√®les et datasets sont centralis√©s et synchronis√©s automatiquement lors du d√©ploiement.*


## 7. Bonnes pratiques
- Conserver la coh√©rence des versions de `scikit-learn` entre entra√Ænement et production.  
- V√©rifier que les volumes `/app/data` et `/app/models` sont bien mont√©s avant chaque d√©ploiement.  
- Utiliser `joblib` pour s√©rialiser les mod√®les et preprocessors.  
- Sauvegarder les notebooks avant tout r√©entra√Ænement.  

---

## 8. R√©f√©rences
- [API ADEME ‚Äì Donn√©es DPE](https://data.ademe.fr/)  
- [Documentation Streamlit](https://docs.streamlit.io/)  
- [Documentation FastAPI](https://fastapi.tiangolo.com/)  
- [Documentation Koyeb](https://www.koyeb.com/docs)  
