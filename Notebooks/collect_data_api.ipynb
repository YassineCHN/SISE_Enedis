{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd4b2a6",
   "metadata": {},
   "source": [
    "## COLLECTE DES DONNEES (API ADEME) NEUFS ET EXISTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a1a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import datetime as dt\n",
    "from requests.exceptions import ChunkedEncodingError, ConnectionError\n",
    "from urllib3.exceptions import ProtocolError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1462830",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2760a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sch√©ma charg√© pour existants : 229 colonnes.\n",
      "[INFO] Sch√©ma charg√© pour neufs : 209 colonnes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "DATASETS = {\n",
    "    \"existants\":\"https://data.ademe.fr/data-fair/api/v1/datasets/dpe03existant/lines\",\n",
    "    \"neufs\":\"https://data.ademe.fr/data-fair/api/v1/datasets/dpe02neuf/lines\",\n",
    "}\n",
    "SCHEMA_COLS = {}\n",
    "for label, url in DATASETS.items():\n",
    "    try:\n",
    "        r = requests.get(url.replace(\"/lines\", \"/schema\"))\n",
    "        r.raise_for_status()\n",
    "        schema_cols = [f[\"key\"] for f in r.json()]\n",
    "        SCHEMA_COLS[label] = schema_cols\n",
    "        print(f\"[INFO] Sch√©ma charg√© pour {label} : {len(schema_cols)} colonnes.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Impossible de charger le sch√©ma pour {label}: {e}\")\n",
    "        SCHEMA_COLS[label] = None\n",
    "\n",
    "\n",
    "DEPT_CODE = \"73\"  # c'est le champ √† modifier pour choisir le d√©partement vis√©\n",
    "CP_PATTERN = f\"{DEPT_CODE}*\" # sert √† formatter le Code d√©partement pour la requ√™te API, 69* ‚Üí CP commen√ßant par 69\n",
    "YEARS = range(2021, 2026)   # p√©riode test\n",
    "PAGE_SIZE = 1200\n",
    "\n",
    "OUT = {\n",
    "    \"existants\": os.path.join(DATA_DIR,f\"donnees_dpe_existants_{DEPT_CODE}.csv\"),\n",
    "    \"neufs\":     os.path.join(DATA_DIR,f\"donnees_dpe_neufs_{DEPT_CODE}.csv\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a665859",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fa2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retries = Retry(\n",
    "    total=5,\n",
    "    connect=3,\n",
    "    read=3,\n",
    "    backoff_factor=0.6,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\"],\n",
    ")\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7776f3",
   "metadata": {},
   "source": [
    "## FONCTIONS UTILITAIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de533ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_first_page(base_url: str, year: int):\n",
    "    \"\"\"R√©cup√®re la premi√®re page pour l'ann√©e donn√©e.\"\"\"\n",
    "    borne1 = f\"{year}-01-01\"\n",
    "    borne2 = f\"{year}-12-31\"\n",
    "    params = {\n",
    "        \"size\": PAGE_SIZE,\n",
    "        \"sort\":\"date_reception_dpe\", # tri par date croissante\n",
    "        \"q\": CP_PATTERN,\n",
    "        \"q_fields\": \"code_postal_ban\",\n",
    "        \"qs\": f\"date_reception_dpe:[{borne1} TO {borne2}]\",\n",
    "    }\n",
    "    r = session.get(base_url, params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def fetch_next_page(next_url: str, max_retries: int = 3, delay: float = 5.0):\n",
    "    \"\"\"R√©cup√®re la page suivante √† partir du champ 'next' avec tol√©rance aux coupures r√©seau.\"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            r = session.get(next_url, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "\n",
    "        except (ChunkedEncodingError, ConnectionError, ProtocolError) as e:\n",
    "            print(f\"[WARN] Connexion interrompue (tentative {attempt}/{max_retries}) : {e}\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(delay * attempt)  # backoff progressif\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"[ERROR] √âchec permanent apr√®s {max_retries} tentatives. Page ignor√©e.\")\n",
    "                return {\"results\": [], \"next\": None}\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"[ERROR] Erreur HTTP inattendue : {e}\")\n",
    "            time.sleep(delay)\n",
    "    return {\"results\": [], \"next\": None}\n",
    "\n",
    "def append_to_csv(df: pd.DataFrame, path: str, header_manager: dict):\n",
    "    \"\"\"√âcrit ou ajoute au CSV en respectant le sch√©ma initial.\"\"\"\n",
    "    if header_manager.get(\"columns\") is None:\n",
    "        header_manager[\"columns\"] = list(df.columns)\n",
    "        df = df.reindex(columns=header_manager[\"columns\"])\n",
    "        df.to_csv(path, index=False, mode=\"w\", header=True)\n",
    "    else:\n",
    "        df = df.reindex(columns=header_manager[\"columns\"])\n",
    "        df.to_csv(path, index=False, mode=\"a\", header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628fe7f",
   "metadata": {},
   "source": [
    "## COLLECTE PRINCIPALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7448b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dpe(label: str, base_url: str, out_csv: str):\n",
    "    header_manager = {\"columns\": None}\n",
    "    total_rows_written = 0\n",
    "    print(f\"\\n=== COLLECTE [{label.upper()}] ===\")\n",
    "\n",
    "    # --- V√©rification existence du fichier ---\n",
    "    if os.path.exists(out_csv):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(out_csv, nrows=1)\n",
    "            header_manager[\"columns\"] = list(existing_df.columns)\n",
    "            print(f\"[INFO] Fichier existant d√©tect√© : les nouvelles donn√©es seront ajout√©es √† la suite ({out_csv}).\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Impossible de lire le fichier existant ({e}), il sera recr√©√©.\")\n",
    "\n",
    "    for year in YEARS:\n",
    "        print(f\"\\n--- Ann√©e {year} ---\")\n",
    "        start_time = time.time()\n",
    "        page = 1\n",
    "        js = fetch_first_page(base_url, year)\n",
    "        next_url = js.get(\"next\")\n",
    "\n",
    "        while True:\n",
    "            results = js.get(\"results\", [])\n",
    "            if not results:\n",
    "                print(f\"[INFO] Aucune donn√©e pour {year}, page {page}\")\n",
    "                break\n",
    "\n",
    "            df_page = pd.DataFrame(results)\n",
    "            # --- Harmoniser les colonnes selon le sch√©ma ADEME ---\n",
    "            schema_cols = SCHEMA_COLS.get(label)\n",
    "            if schema_cols:\n",
    "                 df_page = df_page.reindex(columns=schema_cols)\n",
    "            append_to_csv(df_page, out_csv, header_manager)\n",
    "            total_rows_written += len(df_page)\n",
    "\n",
    "            # --- Estimation du temps total apr√®s la premi√®re page ---\n",
    "            if page == 1:\n",
    "                elapsed = time.time() - start_time  # start_time d√©fini avant la boucle ann√©e\n",
    "                if js.get(\"total\"):\n",
    "                    estimated_total_time = (js[\"total\"] / PAGE_SIZE) * elapsed\n",
    "                    print(f\"[INFO] Estimation de dur√©e pour {year}: {dt.timedelta(seconds=int(estimated_total_time))}\")\n",
    "\n",
    "            print(f\"Page {page:>3} | lignes: {len(df_page):>4} | total cumul√©: {total_rows_written:,}\")\n",
    "\n",
    "            if not next_url:\n",
    "                break  # plus de pages\n",
    "\n",
    "            # Pause douce pour √©viter le throttling\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            # Page suivante\n",
    "            js = fetch_next_page(next_url)\n",
    "            next_url = js.get(\"next\")\n",
    "            page += 1\n",
    "\n",
    "    print(f\"\\n‚úÖ Termin√© [{label}] : {out_csv} | {total_rows_written:,} lignes totales.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c82883",
   "metadata": {},
   "source": [
    "## EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1841afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COLLECTE [NEUFS] ===\n",
      "\n",
      "--- Ann√©e 2021 ---\n",
      "[INFO] Estimation de dur√©e pour 2021: 0:00:06\n",
      "Page   1 | lignes:  975 | total cumul√©: 975\n",
      "\n",
      "--- Ann√©e 2022 ---\n",
      "[INFO] Estimation de dur√©e pour 2022: 0:00:17\n",
      "Page   1 | lignes: 1200 | total cumul√©: 2,175\n",
      "Page   2 | lignes: 1200 | total cumul√©: 3,375\n",
      "Page   3 | lignes:  277 | total cumul√©: 3,652\n",
      "\n",
      "--- Ann√©e 2023 ---\n",
      "[INFO] Estimation de dur√©e pour 2023: 0:00:16\n",
      "Page   1 | lignes: 1200 | total cumul√©: 4,852\n",
      "Page   2 | lignes: 1200 | total cumul√©: 6,052\n",
      "Page   3 | lignes:   70 | total cumul√©: 6,122\n",
      "\n",
      "--- Ann√©e 2024 ---\n",
      "[INFO] Estimation de dur√©e pour 2024: 0:00:19\n",
      "Page   1 | lignes: 1200 | total cumul√©: 7,322\n",
      "Page   2 | lignes: 1200 | total cumul√©: 8,522\n",
      "Page   3 | lignes:  427 | total cumul√©: 8,949\n",
      "\n",
      "--- Ann√©e 2025 ---\n",
      "[INFO] Estimation de dur√©e pour 2025: 0:00:13\n",
      "Page   1 | lignes: 1200 | total cumul√©: 10,149\n",
      "Page   2 | lignes:  667 | total cumul√©: 10,816\n",
      "\n",
      "‚úÖ Termin√© [neufs] : ../data\\donnees_dpe_neufs_73.csv | 10,816 lignes totales.\n",
      "\n",
      "\n",
      "üéØ Collecte neufs (73) termin√©e\n"
     ]
    }
   ],
   "source": [
    "#neufs\n",
    "collect_dpe(\"neufs\",DATASETS[\"neufs\"],OUT[\"neufs\"])\n",
    "print(f\"\\nüéØ Collecte neufs ({DEPT_CODE}) termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ad36bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COLLECTE [EXISTANTS] ===\n",
      "\n",
      "--- Ann√©e 2021 ---\n",
      "[INFO] Estimation de dur√©e pour 2021: 0:00:34\n",
      "Page   1 | lignes: 1200 | total cumul√©: 1,200\n",
      "Page   2 | lignes: 1200 | total cumul√©: 2,400\n",
      "Page   3 | lignes: 1200 | total cumul√©: 3,600\n",
      "Page   4 | lignes: 1200 | total cumul√©: 4,800\n",
      "Page   5 | lignes:  828 | total cumul√©: 5,628\n",
      "\n",
      "--- Ann√©e 2022 ---\n",
      "[INFO] Estimation de dur√©e pour 2022: 0:04:14\n",
      "Page   1 | lignes: 1200 | total cumul√©: 6,828\n",
      "Page   2 | lignes: 1200 | total cumul√©: 8,028\n",
      "Page   3 | lignes: 1200 | total cumul√©: 9,228\n",
      "Page   4 | lignes: 1200 | total cumul√©: 10,428\n",
      "Page   5 | lignes: 1200 | total cumul√©: 11,628\n",
      "Page   6 | lignes: 1200 | total cumul√©: 12,828\n",
      "Page   7 | lignes: 1200 | total cumul√©: 14,028\n",
      "Page   8 | lignes: 1200 | total cumul√©: 15,228\n",
      "Page   9 | lignes: 1200 | total cumul√©: 16,428\n",
      "Page  10 | lignes: 1200 | total cumul√©: 17,628\n",
      "Page  11 | lignes: 1200 | total cumul√©: 18,828\n",
      "Page  12 | lignes: 1200 | total cumul√©: 20,028\n",
      "Page  13 | lignes: 1200 | total cumul√©: 21,228\n",
      "Page  14 | lignes: 1200 | total cumul√©: 22,428\n",
      "Page  15 | lignes: 1200 | total cumul√©: 23,628\n",
      "Page  16 | lignes: 1200 | total cumul√©: 24,828\n",
      "Page  17 | lignes: 1200 | total cumul√©: 26,028\n",
      "Page  18 | lignes: 1142 | total cumul√©: 27,170\n",
      "\n",
      "--- Ann√©e 2023 ---\n",
      "[INFO] Estimation de dur√©e pour 2023: 0:06:39\n",
      "Page   1 | lignes: 1200 | total cumul√©: 28,370\n",
      "Page   2 | lignes: 1200 | total cumul√©: 29,570\n",
      "Page   3 | lignes: 1200 | total cumul√©: 30,770\n",
      "Page   4 | lignes: 1200 | total cumul√©: 31,970\n",
      "Page   5 | lignes: 1200 | total cumul√©: 33,170\n",
      "Page   6 | lignes: 1200 | total cumul√©: 34,370\n",
      "Page   7 | lignes: 1200 | total cumul√©: 35,570\n",
      "Page   8 | lignes: 1200 | total cumul√©: 36,770\n",
      "Page   9 | lignes: 1200 | total cumul√©: 37,970\n",
      "Page  10 | lignes: 1200 | total cumul√©: 39,170\n",
      "Page  11 | lignes: 1200 | total cumul√©: 40,370\n",
      "Page  12 | lignes: 1200 | total cumul√©: 41,570\n",
      "Page  13 | lignes: 1200 | total cumul√©: 42,770\n",
      "Page  14 | lignes: 1200 | total cumul√©: 43,970\n",
      "Page  15 | lignes: 1200 | total cumul√©: 45,170\n",
      "Page  16 | lignes: 1200 | total cumul√©: 46,370\n",
      "Page  17 | lignes: 1200 | total cumul√©: 47,570\n",
      "Page  18 | lignes: 1200 | total cumul√©: 48,770\n",
      "Page  19 | lignes: 1200 | total cumul√©: 49,970\n",
      "Page  20 | lignes: 1200 | total cumul√©: 51,170\n",
      "Page  21 | lignes: 1200 | total cumul√©: 52,370\n",
      "Page  22 | lignes: 1200 | total cumul√©: 53,570\n",
      "Page  23 | lignes: 1200 | total cumul√©: 54,770\n",
      "Page  24 | lignes: 1200 | total cumul√©: 55,970\n",
      "Page  25 | lignes: 1200 | total cumul√©: 57,170\n",
      "Page  26 | lignes: 1200 | total cumul√©: 58,370\n",
      "Page  27 | lignes: 1200 | total cumul√©: 59,570\n",
      "Page  28 | lignes:  792 | total cumul√©: 60,362\n",
      "\n",
      "--- Ann√©e 2024 ---\n",
      "[INFO] Estimation de dur√©e pour 2024: 0:05:31\n",
      "Page   1 | lignes: 1200 | total cumul√©: 61,562\n",
      "Page   2 | lignes: 1200 | total cumul√©: 62,762\n",
      "Page   3 | lignes: 1200 | total cumul√©: 63,962\n",
      "Page   4 | lignes: 1200 | total cumul√©: 65,162\n",
      "Page   5 | lignes: 1200 | total cumul√©: 66,362\n",
      "Page   6 | lignes: 1200 | total cumul√©: 67,562\n",
      "Page   7 | lignes: 1200 | total cumul√©: 68,762\n",
      "Page   8 | lignes: 1200 | total cumul√©: 69,962\n",
      "Page   9 | lignes: 1200 | total cumul√©: 71,162\n",
      "Page  10 | lignes: 1200 | total cumul√©: 72,362\n",
      "Page  11 | lignes: 1200 | total cumul√©: 73,562\n",
      "Page  12 | lignes: 1200 | total cumul√©: 74,762\n",
      "Page  13 | lignes: 1200 | total cumul√©: 75,962\n",
      "Page  14 | lignes: 1200 | total cumul√©: 77,162\n",
      "Page  15 | lignes: 1200 | total cumul√©: 78,362\n",
      "Page  16 | lignes: 1200 | total cumul√©: 79,562\n",
      "Page  17 | lignes: 1200 | total cumul√©: 80,762\n",
      "Page  18 | lignes: 1200 | total cumul√©: 81,962\n",
      "Page  19 | lignes: 1200 | total cumul√©: 83,162\n",
      "Page  20 | lignes: 1200 | total cumul√©: 84,362\n",
      "Page  21 | lignes: 1200 | total cumul√©: 85,562\n",
      "Page  22 | lignes: 1200 | total cumul√©: 86,762\n",
      "Page  23 | lignes:  429 | total cumul√©: 87,191\n",
      "\n",
      "--- Ann√©e 2025 ---\n",
      "[INFO] Estimation de dur√©e pour 2025: 0:04:55\n",
      "Page   1 | lignes: 1200 | total cumul√©: 88,391\n",
      "Page   2 | lignes: 1200 | total cumul√©: 89,591\n",
      "Page   3 | lignes: 1200 | total cumul√©: 90,791\n",
      "Page   4 | lignes: 1200 | total cumul√©: 91,991\n",
      "Page   5 | lignes: 1200 | total cumul√©: 93,191\n",
      "Page   6 | lignes: 1200 | total cumul√©: 94,391\n",
      "Page   7 | lignes: 1200 | total cumul√©: 95,591\n",
      "Page   8 | lignes: 1200 | total cumul√©: 96,791\n",
      "Page   9 | lignes: 1200 | total cumul√©: 97,991\n",
      "Page  10 | lignes: 1200 | total cumul√©: 99,191\n",
      "Page  11 | lignes: 1200 | total cumul√©: 100,391\n",
      "Page  12 | lignes: 1200 | total cumul√©: 101,591\n",
      "Page  13 | lignes: 1200 | total cumul√©: 102,791\n",
      "Page  14 | lignes: 1200 | total cumul√©: 103,991\n",
      "Page  15 | lignes: 1200 | total cumul√©: 105,191\n",
      "Page  16 | lignes: 1200 | total cumul√©: 106,391\n",
      "Page  17 | lignes: 1200 | total cumul√©: 107,591\n",
      "Page  18 | lignes: 1200 | total cumul√©: 108,791\n",
      "Page  19 | lignes: 1200 | total cumul√©: 109,991\n",
      "Page  20 | lignes:  535 | total cumul√©: 110,526\n",
      "\n",
      "‚úÖ Termin√© [existants] : ../data\\donnees_dpe_existants_73.csv | 110,526 lignes totales.\n",
      "\n",
      "\n",
      "üéØ Collecte existants (73) termin√©e\n"
     ]
    }
   ],
   "source": [
    "#existants\n",
    "collect_dpe(\"existants\",DATASETS[\"existants\"],OUT[\"existants\"])\n",
    "\n",
    "print(f\"\\nüéØ Collecte existants ({DEPT_CODE}) termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d89f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ychen\\AppData\\Local\\Temp\\ipykernel_50596\\2197104736.py:3: DtypeWarning: Columns (7,26,39,51,201,202,203,204,208,213) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_exist = pd.read_csv(f\"../data/donnees_dpe_existants_{DEPT_CODE}.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existants : (110526, 229)\n",
      "Neufs : (10816, 209)\n",
      "\n",
      "Ann√©es existants : date_reception_dpe\n",
      "2021     5628\n",
      "2022    21542\n",
      "2023    33192\n",
      "2024    26829\n",
      "2025    23335\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ann√©es neufs : date_reception_dpe\n",
      "2021     975\n",
      "2022    2677\n",
      "2023    2470\n",
      "2024    2827\n",
      "2025    1867\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ychen\\AppData\\Local\\Temp\\ipykernel_50596\\2197104736.py:4: DtypeWarning: Columns (31,37,136,137,138,139,140,143,144,145,147,148,149,151,152,153,154,157,158,159,166,169,170,171,175,177,178,179,180,191,199) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_neuf = pd.read_csv(f\"../data/donnees_dpe_neufs_{DEPT_CODE}.csv\")\n"
     ]
    }
   ],
   "source": [
    "# V√©rif nb lignes + v√©rif ANNEE\n",
    "\n",
    "df_exist = pd.read_csv(f\"../data/donnees_dpe_existants_{DEPT_CODE}.csv\")\n",
    "df_neuf = pd.read_csv(f\"../data/donnees_dpe_neufs_{DEPT_CODE}.csv\")\n",
    "\n",
    "print(\"Existants :\", df_exist.shape)\n",
    "print(\"Neufs :\", df_neuf.shape)\n",
    "\n",
    "# V√©rifier les ann√©es couvertes\n",
    "print(\"\\nAnn√©es existants :\", df_exist[\"date_reception_dpe\"].str[:4].value_counts().sort_index())\n",
    "print(\"\\nAnn√©es neufs :\", df_neuf[\"date_reception_dpe\"].str[:4].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717b716",
   "metadata": {},
   "source": [
    "## Relance sur ANNEE, en cas de plantage pour dpe existant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1027073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ychen\\AppData\\Local\\Temp\\ipykernel_38628\\1104308851.py:6: DtypeWarning: Columns (7,26,51,213) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant : 75483\n",
      "Apr√®s suppression ann√©es [2025] : 69448\n",
      "‚úÖ Fichier nettoy√©, pr√™t pour re-collecte [2025]\n",
      "\n",
      "=== COLLECTE [EXISTANTS] ===\n",
      "[INFO] Fichier existant d√©tect√© : les nouvelles donn√©es seront ajout√©es √† la suite (../data\\donnees_dpe_existants_71.csv).\n",
      "\n",
      "--- Ann√©e 2025 ---\n",
      "[INFO] Estimation de dur√©e pour 2025: 0:02:53\n",
      "Page   1 | lignes: 1200 | total cumul√©: 1,200\n",
      "Page   2 | lignes: 1200 | total cumul√©: 2,400\n",
      "Page   3 | lignes: 1200 | total cumul√©: 3,600\n",
      "Page   4 | lignes: 1200 | total cumul√©: 4,800\n",
      "Page   5 | lignes: 1200 | total cumul√©: 6,000\n",
      "Page   6 | lignes: 1200 | total cumul√©: 7,200\n",
      "Page   7 | lignes: 1200 | total cumul√©: 8,400\n",
      "Page   8 | lignes: 1200 | total cumul√©: 9,600\n",
      "Page   9 | lignes: 1200 | total cumul√©: 10,800\n",
      "Page  10 | lignes: 1200 | total cumul√©: 12,000\n",
      "Page  11 | lignes: 1200 | total cumul√©: 13,200\n",
      "Page  12 | lignes: 1200 | total cumul√©: 14,400\n",
      "Page  13 | lignes: 1200 | total cumul√©: 15,600\n",
      "Page  14 | lignes:  387 | total cumul√©: 15,987\n",
      "\n",
      "‚úÖ Termin√© [existants] : ../data\\donnees_dpe_existants_71.csv | 15,987 lignes totales.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ann√©es √† relancer\n",
    "YEARS = [2025]  # ou plusieurs : [2023, 2025]\n",
    "\n",
    "# Nettoyer les lignes d√©j√† pr√©sentes dans le CSV, pour ces ann√©es\n",
    "path = f\"../data/donnees_dpe_existants_{DEPT_CODE}.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"Avant :\", len(df))\n",
    "\n",
    "# Convertir les ann√©es en cha√Ænes et filtrer dynamiquement\n",
    "years_str = [str(y) for y in YEARS]\n",
    "df = df[~df[\"date_reception_dpe\"].astype(str).str[:4].isin(years_str)]\n",
    "\n",
    "print(\"Apr√®s suppression ann√©es\", YEARS, \":\", len(df))\n",
    "\n",
    "# Sauvegarde du fichier nettoy√©\n",
    "df.to_csv(path, index=False)\n",
    "print(\"‚úÖ Fichier nettoy√©, pr√™t pour re-collecte\", YEARS)\n",
    "\n",
    "# Ex√©cution relance\n",
    "collect_dpe(\"existants\", DATASETS[\"existants\"], OUT[\"existants\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac9d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ychen\\AppData\\Local\\Temp\\ipykernel_38628\\3833362665.py:2: DtypeWarning: Columns (7,26,51,213) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lignes finale :  85435\n"
     ]
    }
   ],
   "source": [
    "path = f\"../data/donnees_dpe_existants_{DEPT_CODE}.csv\"\n",
    "df = pd.read_csv(path)\n",
    "print(\"Total lignes finale : \",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab34b2",
   "metadata": {},
   "source": [
    "## Test Size Requ√™tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d88235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test size=500 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Test size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m duration = time.time() - start\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:1251\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m decoded = \u001b[38;5;28mself\u001b[39m._decode(\n\u001b[32m   1253\u001b[39m     chunk, decode_content=decode_content, flush_decoder=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1254\u001b[39m )\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py:1188\u001b[39m, in \u001b[36mHTTPResponse._handle_chunk\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_left = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt < \u001b[38;5;28mself\u001b[39m.chunk_left:\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_left = \u001b[38;5;28mself\u001b[39m.chunk_left - amt\n\u001b[32m   1190\u001b[39m     returned_chunk = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:642\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    637\u001b[39m \n\u001b[32m    638\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    644\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ychen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#test size requetes\n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"https://data.ademe.fr/data-fair/api/v1/datasets/dpe03existant/lines\"\n",
    "params_template = {\n",
    "    \"q\": \"69*\",\n",
    "    \"q_fields\": \"code_postal_ban\",\n",
    "    \"qs\": \"date_reception_dpe:[2022-01-01 TO 2022-12-31]\"\n",
    "}\n",
    "\n",
    "sizes = [500, 1000, 2000, 5000, 10000, 11000]  # tailles √† tester\n",
    "\n",
    "for size in sizes:\n",
    "    params = dict(params_template)\n",
    "    params[\"size\"] = size\n",
    "\n",
    "    print(f\"\\n--- Test size={size} ---\")\n",
    "    start = time.time()\n",
    "    r = requests.get(BASE_URL, params=params, timeout=120)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print(f\"Erreur {r.status_code} : {r.text[:300]}\")\n",
    "        continue\n",
    "\n",
    "    js = r.json()\n",
    "    n_results = len(js.get(\"results\", []))\n",
    "    total = js.get(\"total\", \"N/A\")\n",
    "\n",
    "    print(f\"Dur√©e : {duration:.2f}s | Lignes retourn√©es : {n_results} | Total annonc√© : {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test size requetes\n",
    "\n",
    "import time\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"https://data.ademe.fr/data-fair/api/v1/datasets/dpe03existant/lines\"\n",
    "params_template = {\n",
    "    \"q\": \"69*\",\n",
    "    \"q_fields\": \"code_postal_ban\",\n",
    "    \"qs\": \"date_reception_dpe:[2022-01-01 TO 2022-12-31]\"\n",
    "}\n",
    "\n",
    "sizes = [1000, 1100, 1200, 1300, 1400,1500, 1600, 1700, 1800, 1900, 2000]  # tailles √† tester\n",
    "\n",
    "for size in sizes:\n",
    "    params = dict(params_template)\n",
    "    params[\"size\"] = size\n",
    "\n",
    "    print(f\"\\n--- Test size={size} ---\")\n",
    "    start = time.time()\n",
    "    r = requests.get(BASE_URL, params=params, timeout=120)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print(f\"Erreur {r.status_code} : {r.text[:300]}\")\n",
    "        continue\n",
    "\n",
    "    js = r.json()\n",
    "    n_results = len(js.get(\"results\", []))\n",
    "    total = js.get(\"total\", \"N/A\")\n",
    "\n",
    "    print(f\"Dur√©e : {duration:.2f}s | Lignes retourn√©es : {n_results} | Total annonc√© : {total}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_enedis)",
   "language": "python",
   "name": "venv_enedis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
